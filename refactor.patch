diff --git a/CLAUDE.md b/CLAUDE.md
index 7ffe526..44d3fb2 100644
--- a/CLAUDE.md
+++ b/CLAUDE.md
@@ -70,7 +70,7 @@ Two call patterns:
 
 - **Naming**: snake_case for functions/variables, PascalCase for classes
 - **Private members**: prefixed with `_` (e.g., `_rds`, `_running`, `_request_pool`)
-- **Logging**: `logging` module with `LOG_LEVEL` env var (default varies: `ERROR` in server, `INFO` in client); each class creates its own logger via `logging.getLogger(__name__)`
+- **Logging**: `logging` module with `LOG_LEVEL` env var; defaults controlled via `_log_level_default` class attribute (`'ERROR'` in server, `'INFO'` in client). Logger setup is consolidated in `RedisConnection.__init__` using `logging.getLogger(type(self).__module__)`
 - **Type hints**: Used on method signatures (parameters and return types), not enforced strictly
 - **Imports**: Standard library first, then third-party, then local modules
 - **Threading**: Daemon threads for background work (`daemon=True`)
diff --git a/callite/client/rpc_client.py b/callite/client/rpc_client.py
index c67d695..0d244ca 100644
--- a/callite/client/rpc_client.py
+++ b/callite/client/rpc_client.py
@@ -1,5 +1,3 @@
-import asyncio
-import logging
 import os
 import pickle
 import threading
@@ -8,14 +6,8 @@ from callite.shared.redis_connection import RedisConnection
 from callite.rpctypes.request import Request
 
 
-# import pydevd_pycharm
-# pydevd_pycharm.settrace('host.docker.internal', port=4444, stdoutToServer=True, stderrToServer=True)
-# pydevd_pycharm.settrace('localhost', port=4444, stdoutToServer=True, stderrToServer=True)
+TIMEOUT = int(os.getenv('EXECUTION_TIMEOUT', '30'))
 
-TIMEOUT = os.getenv('EXECUTION_TIMEOUT', 30)
-
-log_level = os.getenv('LOG_LEVEL', 'INFO')
-log_level = getattr(logging, log_level.upper(), 'INFO')
 
 def check_and_return(response):
     if response.status == 'error':
@@ -28,10 +20,8 @@ class RPCClient(RedisConnection):
 
     def __init__(self, conn_url: str, service: str, execution_timeout=TIMEOUT, *args, **kwargs) -> None:
         super().__init__(conn_url, service, *args, **kwargs)
-        self._logger = logging.getLogger(__name__)
-        self._logger.addHandler(logging.StreamHandler())
-        self._logger.setLevel(log_level)
         self._request_pool = {}
+        self._pool_lock = threading.Lock()
         self._subscribe_thread = None
         self._subscribe()
         self.execution_timeout = execution_timeout
@@ -43,36 +33,23 @@ class RPCClient(RedisConnection):
         self._subscribe_thread.start()
 
     def _pull_from_redis(self):
-        async def _on_delivery(message):
-            # data = json.loads(message['data'].decode('utf-8'))
-            data = pickle.loads(message['data'])
-            request_guid = data['request_id']
-            if request_guid not in self._request_pool:
-                return
-            lock, _ = self._request_pool.pop(request_guid)
-            self._request_pool[request_guid] = (lock, data)
-            lock.release()
-
-        # TODO: handle poisonous messages from redis (e.g. non-json, old messages, etc.)
         while self._running:
             message: dict | None = self.channel.get_message(ignore_subscribe_messages=True, timeout=100)
             if not message: continue
             if not message['data']: continue
-            asyncio.run(_on_delivery(message))
+            data = pickle.loads(message['data'])
+            request_guid = data['request_id']
+            with self._pool_lock:
+                if request_guid not in self._request_pool:
+                    continue
+                lock, _ = self._request_pool.pop(request_guid)
+                self._request_pool[request_guid] = (lock, data)
+            lock.release()
 
     def publish(self, method: str, *args, **kwargs):
-
-        async def _publish():
-            request = Request(method, self._connection_id, None, *args, **kwargs)
-            pickled_request = pickle.dumps(request)
-            self._rds.xadd(f'{self._queue_prefix}/request/{self._service}', {'data': pickled_request})
-
-        try:
-            loop = asyncio.get_running_loop()
-            loop.create_task(_publish())
-        except RuntimeError:
-            # No event loop is running, create a new one
-            asyncio.run(_publish())
+        request = Request(method, self._connection_id, None, *args, **kwargs)
+        pickled_request = pickle.dumps(request)
+        self._rds.xadd(f'{self._queue_prefix}/request/{self._service}', {'data': pickled_request})
 
     def execute(self, method: str, *args, **kwargs) -> dict:
         """
@@ -103,7 +80,8 @@ class RPCClient(RedisConnection):
         request_uuid = request.request_id
 
         request_lock = threading.Lock()
-        self._request_pool[request_uuid] = (request_lock, None)
+        with self._pool_lock:
+            self._request_pool[request_uuid] = (request_lock, None)
         self._logger.debug(f'Acquiring lock: {request_uuid}')
         request_lock.acquire()
         pickled_request = pickle.dumps(request)
@@ -113,7 +91,8 @@ class RPCClient(RedisConnection):
         self._logger.debug(f'Waiting for response: {request_uuid}')
         lock_success = request_lock.acquire(timeout=self.execution_timeout)
         self._logger.debug(f'Response result: {request_uuid}')
-        lock, data = self._request_pool.pop(request_uuid)
+        with self._pool_lock:
+            lock, data = self._request_pool.pop(request_uuid)
         if lock_success:
             self._logger.debug(f'Releasing lock: {request_uuid}')
             response = data['data']
@@ -126,7 +105,3 @@ class RPCClient(RedisConnection):
         if self._subscribe_thread:
             self._subscribe_thread.join()
         super().close()
-
-if __name__ == "__main__":
-    client = RPCClient("redis://localhost:6379/0", "db")
-    client.execute('get_question',2)
\ No newline at end of file
diff --git a/callite/rpctypes/message_base.py b/callite/rpctypes/message_base.py
index 7a1eae3..fde34d8 100644
--- a/callite/rpctypes/message_base.py
+++ b/callite/rpctypes/message_base.py
@@ -1,3 +1,3 @@
-class MessageBase(object):
+class MessageBase:
     def __init__(self, message_id):
         self.message_id: str = message_id
diff --git a/callite/rpctypes/response.py b/callite/rpctypes/response.py
index 777b4d1..d981bf4 100644
--- a/callite/rpctypes/response.py
+++ b/callite/rpctypes/response.py
@@ -1,5 +1,3 @@
-import json
-
 from callite.rpctypes.message_base import MessageBase
 
 
diff --git a/callite/server/rpc_server.py b/callite/server/rpc_server.py
index ae15371..7991cde 100644
--- a/callite/server/rpc_server.py
+++ b/callite/server/rpc_server.py
@@ -1,76 +1,58 @@
 import pickle
-import logging
-import os
 import threading
 import time
-from types import FunctionType
-from typing import Any, Callable
+from typing import Callable
 
 import redis
-from tenacity import *
+from tenacity import retry
 
 from callite.rpctypes.response import Response
 from callite.shared.redis_connection import RedisConnection
 
 
-# import pydevd_pycharm
-# pydevd_pycharm.settrace('localhost', port=4444, stdoutToServer=True, stderrToServer=True)
-
-log_level = os.getenv('LOG_LEVEL', 'ERROR')
-log_level = getattr(logging, log_level.upper(), 'ERROR')
-
-# TODO: Check method calls and parameters
 class RPCServer(RedisConnection):
+    _log_level_default = 'ERROR'
+
     def __init__(self, conn_url: str, service: str, *args, **kwargs):
         super().__init__(conn_url, service, *args, **kwargs)
         self._registered_methods = {}
         self._xread_groupname = kwargs.get('xread_groupname', 'generic')
-        # self._encoded_xread_groupname = self._xread_groupname.encode('utf-8')
-
-        self._logger = logging.getLogger(__name__)
-        self._logger.addHandler(logging.StreamHandler())
-        self._logger.setLevel(log_level)
-        # TODO: handle thread exceptions and dispose of threads
 
         self._subscribe_redis_thread = threading.Thread(target=self._subscribe_redis, daemon=True)
         self._subscribe_redis_thread.start()
         self._logger.debug("Server started")
 
-    def subscribe(self, handler: FunctionType | Callable, method_name: str | None = None) -> None:
+    @property
+    def _request_stream(self) -> str:
+        return f'{self._queue_prefix}/request/{self._service}'
+
+    def subscribe(self, handler: Callable, method_name: str | None = None) -> None:
         self.register_method(handler, method_name, False)
 
-    def register(self, handler: FunctionType | Callable, method_name: str | None = None) -> Callable:
+    def register(self, handler: Callable, method_name: str | None = None) -> Callable:
         return self.register_method(handler, method_name, True)
 
-    def register_method(self, handler: FunctionType | Callable, method_name: str | None = None, returns: bool = True) -> Callable:
+    def register_method(self, handler: Callable, method_name: str | None = None, returns: bool = True) -> Callable:
         method_name = method_name or handler.__name__
         self._logger.debug(f"Registering method {method_name}")
         self._registered_methods[method_name] = {'func': handler, 'returns': returns}
         return handler
 
     def run_forever(self) -> None:
-        while self._running: time.sleep(1000000)
+        while self._running:
+            time.sleep(1000000)
 
     @retry
     def _subscribe_redis(self):
         while self._running:
             if not self._check_connection():
                 self._connect()
-            if not self._check_xgroup_exists():
-                self._create_redis_group()
+            self._ensure_consumer_group()
             self._logger.debug("Checking for messages")
             messages = self._read_messages_from_redis()
             self._logger.debug(f"Received {len(messages)} messages")
             self._process_messages(messages)
 
-            # try:
-            #     self._rds.ping()
-            #     self._logger.debug("Connection is alive!")
-            # except:
-            #     # Handle connection error if needed
-            #     self._rds = redis.Redis.from_url(self._conn_url)
-            #     self._logger.debug("Connection error!")
-
     def _check_connection(self):
         try:
             self._rds.ping()
@@ -78,28 +60,19 @@ class RPCServer(RedisConnection):
         except redis.exceptions.ConnectionError:
             return False
 
-    def _check_xgroup_exists(self):
+    def _ensure_consumer_group(self):
         try:
-            info = self._rds.xinfo_groups(f'{self._queue_prefix}/request/{self._service}')
-        # if len(info) != 0 and info[0]['name'] != self._encoded_xread_groupname:
-            if len(info) != 0:
-                self._logger.debug('GROUP exists')
-                return True
-        except redis.exceptions.ResponseError:
-            return False
-
-        return False
-
-    def _create_redis_group(self):
-        try:
-            self._rds.xgroup_create(f'{self._queue_prefix}/request/{self._service}', self._xread_groupname, mkstream=True)
+            self._rds.xgroup_create(self._request_stream, self._xread_groupname, mkstream=True)
         except redis.exceptions.ResponseError as e:
-            if "name already exists" not in str(e): raise
+            if "BUSYGROUP" not in str(e) and "already exists" not in str(e):
+                raise
 
     def _read_messages_from_redis(self):
-        messages = self._rds.xreadgroup(self._xread_groupname, self._connection_id, {f'{self._queue_prefix}/request/{self._service}': '>'}, count=1, block=1000, noack=True)
-        self._logger.debug(f"{len(messages)} messages received from {self._queue_prefix}/request/{self._service}")
-
+        messages = self._rds.xreadgroup(
+            self._xread_groupname, self._connection_id,
+            {self._request_stream: '>'}, count=1, block=1000
+        )
+        self._logger.debug(f"{len(messages)} messages received from {self._request_stream}")
         return messages
 
     def _process_messages(self, messages):
@@ -108,47 +81,35 @@ class RPCServer(RedisConnection):
                 message_id, message_data = _message
                 request = pickle.loads(message_data[b'data'])
                 self._logger.info(f"Processing message {message_id} with data: {request}")
-                self._handle_messages(request, message_id)
-
-    def _handle_messages(self, request, message_id):
-        threading.Thread(target=self._process_single, args=(request, message_id), daemon=True).start()
+                threading.Thread(target=self._process_single, args=(request, message_id), daemon=True).start()
 
     def _process_single(self, request, message_id):
+        self._rds.xack(self._request_stream, self._xread_groupname, message_id)
 
-        self._rds.xack(f'{self._queue_prefix}/request/{self._service}', self._xread_groupname, message_id)
         if request.method not in self._registered_methods:
-            raise Exception(f"Method {request.method} not registered")
+            self._logger.error(f"Method {request.method} not registered")
+            error_response = Response(self._service, message_id, status='error', error=f"Method {request.method} not registered")
+            payload = pickle.dumps({'data': error_response, 'request_id': request.request_id})
+            self._rds.publish(f'{self._queue_prefix}/response/{request.client_id}', payload)
+            return
 
-        returns = self._registered_methods[request.method]['returns']
-        if returns:
-            response = self._call_registered_method(request.method, message_id, *request.args, **request.kwargs)
+        method_info = self._registered_methods[request.method]
+        if method_info['returns']:
+            response = self._call_method(request.method, message_id, *request.args, **request.kwargs)
             payload = pickle.dumps({'data': response, 'request_id': request.request_id})
             self._rds.publish(f'{self._queue_prefix}/response/{request.client_id}', payload)
             self._logger.info(f"Processed message {message_id} and response published to {self._queue_prefix}/response/{request.request_id}")
         else:
-            self._call_registered_method_no_returns(request.method, message_id, *request.args, **request.kwargs)
+            self._call_method(request.method, message_id, *request.args, **request.kwargs)
             self._logger.info(f"Processed message {message_id} without response")
 
-
-    def _call_registered_method_no_returns(self, method: str, message_id, *args, **kwargs) -> None:
-        try:
-            self._registered_methods[method]['func'](*args, **kwargs)
-            return
-
-        except Exception as e:
-            self._logger.error(e)
-            return
-
-    def _call_registered_method(self, method: str, message_id, *args, **kwargs) -> Any:
+    def _call_method(self, method: str, message_id, *args, **kwargs) -> Response:
         try:
             message_id = message_id.decode('utf-8') if isinstance(message_id, bytes) else message_id
-
             data = self._registered_methods[method]['func'](*args, **kwargs)
-
             response = Response(self._service, message_id)
             response.data = data
             return response
         except Exception as e:
             self._logger.error(e)
-            response = Response(self._service, message_id, status='error', error=str(e))
-            return response
+            return Response(self._service, message_id, status='error', error=str(e))
diff --git a/callite/shared/redis_connection.py b/callite/shared/redis_connection.py
index c521d5a..65a36d9 100644
--- a/callite/shared/redis_connection.py
+++ b/callite/shared/redis_connection.py
@@ -4,19 +4,21 @@ import uuid
 import redis
 from abc import ABC
 
-log_level = os.getenv('LOG_LEVEL', 'INFO')
-log_level = getattr(logging, log_level.upper(), 'INFO')
-
 
 class RedisConnection(ABC):
+    _log_level_default = 'INFO'
+
     def __init__(self, conn_url: str, service: str, *args, **kwargs):
-        self._logger = logging.getLogger(__name__)
-        self._logger.addHandler(logging.StreamHandler())
+        log_level_str = os.getenv('LOG_LEVEL', self._log_level_default)
+        log_level = getattr(logging, log_level_str.upper(), logging.INFO)
+
+        self._logger = logging.getLogger(type(self).__module__)
+        if not self._logger.handlers:
+            self._logger.addHandler(logging.StreamHandler())
         self._logger.setLevel(log_level)
-        self._methods = {}
+
         self._service = service
         self._running = True
-        self._running_threads = []
         self._connection_id = uuid.uuid4().hex
         self._queue_prefix = kwargs.get('queue_prefix', '/callite')
         self._conn_url = conn_url
@@ -27,4 +29,3 @@ class RedisConnection(ABC):
 
     def close(self) -> None:
         self._running = False
-        self._keep_alive_thread.join()
